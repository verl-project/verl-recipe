# GRPO Baseline config for async training with FSDP2
# Uses one_step_off_policy trainer with separate rollout and training GPUs
# Optimized for 2-GPU setup: 1 GPU for vLLM rollout, 1 GPU for FSDP2 training

hydra:
  searchpath:
    - pkg://verl.trainer.config

defaults:
  - ppo_trainer
  - _self_

# Config for the rollout (resource isolation for async training)
rollout:
  nnodes: 1
  n_gpus_per_node: 1

# Trainer resource configuration
trainer:
  nnodes: 1
  n_gpus_per_node: 1

# Actor/Rollout configuration for async mode
actor_rollout_ref:
  hybrid_engine: False
  
  model:
    use_remove_padding: True
    enable_gradient_checkpointing: True
  
  actor:
    strategy: fsdp2
    # PPO clipping
    clip_ratio: 0.2
    clip_ratio_low: 0.2
    clip_ratio_high: 0.28
    
    fsdp_config:
      param_offload: True
      optimizer_offload: True
  
  rollout:
    # Must be turned off for parameter sync
    free_cache_engine: False
    # Must be enabled for log probs calculation
    calculate_log_probs: True
    mode: async
    n: 5
    tensor_model_parallel_size: 1
  
  ref:
    fsdp_config:
      param_offload: True

# Critic configuration (not used in GRPO but required)
critic:
  strategy: fsdp2

# Algorithm configuration
algorithm:
  adv_estimator: grpo
  use_kl_in_reward: False

  # Rollout correction for async training
  rollout_correction:
    bypass_mode: True
    rollout_is: sequence
    rollout_is_threshold: 2.0
